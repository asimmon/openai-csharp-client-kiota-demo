using Microsoft.Kiota.Abstractions.Serialization;
using System.Collections.Generic;
using System.IO;
using System.Linq;
using System;
namespace MyApp.OpenAi.Models {
    public class CreateClassificationRequest : IParsable {
        /// <summary>A list of examples with labels, in the following format:`[[&quot;The movie is so interesting.&quot;, &quot;Positive&quot;], [&quot;It is quite boring.&quot;, &quot;Negative&quot;], ...]`All the label strings will be normalized to be capitalized.You should specify either `examples` or `file`, but not both.</summary>
#if NETSTANDARD2_1_OR_GREATER || NETCOREAPP3_1_OR_GREATER
#nullable enable
        public List<string>? Examples { get; set; }
#nullable restore
#else
        public List<string> Examples { get; set; }
#endif
        /// <summary>The ID of the uploaded file that contains training examples. See [upload file](/docs/api-reference/files/upload) for how to upload a file of the desired format and purpose.You should specify either `examples` or `file`, but not both.</summary>
#if NETSTANDARD2_1_OR_GREATER || NETCOREAPP3_1_OR_GREATER
#nullable enable
        public string? File { get; set; }
#nullable restore
#else
        public string File { get; set; }
#endif
        /// <summary>The set of categories being classified. If not specified, candidate labels will be automatically collected from the examples you provide. All the label strings will be normalized to be capitalized.</summary>
#if NETSTANDARD2_1_OR_GREATER || NETCOREAPP3_1_OR_GREATER
#nullable enable
        public List<string>? Labels { get; set; }
#nullable restore
#else
        public List<string> Labels { get; set; }
#endif
        /// <summary>Modify the likelihood of specified tokens appearing in the completion.Accepts a json object that maps tokens (specified by their token ID in the GPT tokenizer) to an associated bias value from -100 to 100. You can use this [tokenizer tool](/tokenizer?view=bpe) (which works for both GPT-2 and GPT-3) to convert text to token IDs. Mathematically, the bias is added to the logits generated by the model prior to sampling. The exact effect will vary per model, but values between -1 and 1 should decrease or increase likelihood of selection; values like -100 or 100 should result in a ban or exclusive selection of the relevant token.As an example, you can pass `{&quot;50256&quot;: -100}` to prevent the &lt;|endoftext|&gt; token from being generated.</summary>
#if NETSTANDARD2_1_OR_GREATER || NETCOREAPP3_1_OR_GREATER
#nullable enable
        public CreateClassificationRequest_logit_bias? LogitBias { get; set; }
#nullable restore
#else
        public CreateClassificationRequest_logit_bias LogitBias { get; set; }
#endif
        /// <summary>Include the log probabilities on the `logprobs` most likely tokens, as well the chosen tokens. For example, if `logprobs` is 5, the API will return a list of the 5 most likely tokens. The API will always return the `logprob` of the sampled token, so there may be up to `logprobs+1` elements in the response.The maximum value for `logprobs` is 5. If you need more than this, please contact us through our [Help center](https://help.openai.com) and describe your use case.When `logprobs` is set, `completion` will be automatically added into `expand` to get the logprobs.</summary>
        public int? Logprobs { get; set; }
        /// <summary>The maximum number of examples to be ranked by [Search](/docs/api-reference/searches/create) when using `file`. Setting it to a higher value leads to improved accuracy but with increased latency and cost.</summary>
        public int? MaxExamples { get; set; }
        /// <summary>ID of the model to use. You can use the [List models](/docs/api-reference/models/list) API to see all of your available models, or see our [Model overview](/docs/models/overview) for descriptions of them.</summary>
#if NETSTANDARD2_1_OR_GREATER || NETCOREAPP3_1_OR_GREATER
#nullable enable
        public string? Model { get; set; }
#nullable restore
#else
        public string Model { get; set; }
#endif
        /// <summary>Query to be classified.</summary>
#if NETSTANDARD2_1_OR_GREATER || NETCOREAPP3_1_OR_GREATER
#nullable enable
        public string? Query { get; set; }
#nullable restore
#else
        public string Query { get; set; }
#endif
        /// <summary>A special boolean flag for showing metadata. If set to `true`, each document entry in the returned JSON will contain a &quot;metadata&quot; field.This flag only takes effect when `file` is set.</summary>
        public bool? ReturnMetadata { get; set; }
        /// <summary>If set to `true`, the returned JSON will include a &quot;prompt&quot; field containing the final prompt that was used to request a completion. This is mainly useful for debugging purposes.</summary>
        public bool? ReturnPrompt { get; set; }
        /// <summary>ID of the model to use for [Search](/docs/api-reference/searches/create). You can select one of `ada`, `babbage`, `curie`, or `davinci`.</summary>
#if NETSTANDARD2_1_OR_GREATER || NETCOREAPP3_1_OR_GREATER
#nullable enable
        public string? SearchModel { get; set; }
#nullable restore
#else
        public string SearchModel { get; set; }
#endif
        /// <summary>What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.</summary>
        public double? Temperature { get; set; }
        /// <summary>A unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse. [Learn more](/docs/guides/safety-best-practices/end-user-ids).</summary>
#if NETSTANDARD2_1_OR_GREATER || NETCOREAPP3_1_OR_GREATER
#nullable enable
        public string? User { get; set; }
#nullable restore
#else
        public string User { get; set; }
#endif
        /// <summary>
        /// Instantiates a new CreateClassificationRequest and sets the default values.
        /// </summary>
        public CreateClassificationRequest() {
            SearchModel = "ada";
        }
        /// <summary>
        /// Creates a new instance of the appropriate class based on discriminator value
        /// </summary>
        /// <param name="parseNode">The parse node to use to read the discriminator value and create the object</param>
        public static CreateClassificationRequest CreateFromDiscriminatorValue(IParseNode parseNode) {
            _ = parseNode ?? throw new ArgumentNullException(nameof(parseNode));
            return new CreateClassificationRequest();
        }
        /// <summary>
        /// The deserialization information for the current model
        /// </summary>
        public IDictionary<string, Action<IParseNode>> GetFieldDeserializers() {
            return new Dictionary<string, Action<IParseNode>> {
                {"examples", n => { Examples = n.GetCollectionOfPrimitiveValues<string>()?.ToList(); } },
                {"file", n => { File = n.GetStringValue(); } },
                {"labels", n => { Labels = n.GetCollectionOfPrimitiveValues<string>()?.ToList(); } },
                {"logit_bias", n => { LogitBias = n.GetObjectValue<CreateClassificationRequest_logit_bias>(CreateClassificationRequest_logit_bias.CreateFromDiscriminatorValue); } },
                {"logprobs", n => { Logprobs = n.GetIntValue(); } },
                {"max_examples", n => { MaxExamples = n.GetIntValue(); } },
                {"model", n => { Model = n.GetStringValue(); } },
                {"query", n => { Query = n.GetStringValue(); } },
                {"return_metadata", n => { ReturnMetadata = n.GetBoolValue(); } },
                {"return_prompt", n => { ReturnPrompt = n.GetBoolValue(); } },
                {"search_model", n => { SearchModel = n.GetStringValue(); } },
                {"temperature", n => { Temperature = n.GetDoubleValue(); } },
                {"user", n => { User = n.GetStringValue(); } },
            };
        }
        /// <summary>
        /// Serializes information the current object
        /// </summary>
        /// <param name="writer">Serialization writer to use to serialize this model</param>
        public void Serialize(ISerializationWriter writer) {
            _ = writer ?? throw new ArgumentNullException(nameof(writer));
            writer.WriteCollectionOfPrimitiveValues<string>("examples", Examples);
            writer.WriteStringValue("file", File);
            writer.WriteCollectionOfPrimitiveValues<string>("labels", Labels);
            writer.WriteObjectValue<CreateClassificationRequest_logit_bias>("logit_bias", LogitBias);
            writer.WriteIntValue("logprobs", Logprobs);
            writer.WriteIntValue("max_examples", MaxExamples);
            writer.WriteStringValue("model", Model);
            writer.WriteStringValue("query", Query);
            writer.WriteBoolValue("return_metadata", ReturnMetadata);
            writer.WriteBoolValue("return_prompt", ReturnPrompt);
            writer.WriteStringValue("search_model", SearchModel);
            writer.WriteDoubleValue("temperature", Temperature);
            writer.WriteStringValue("user", User);
        }
    }
}
